---
title: "SVI_COVID"
author: "John Rollman"
date: "July 5, 2021"
output: 
  rmarkdown::github_document:
    toc: yes
    toc_depth: '4'
  html_document:
    toc: yes
    toc_depth: '4'
    toc_float: yes
always_allow_html: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Packages Used  
```{r message=FALSE, warning=FALSE, error=FALSE}
library(tidyverse) #Data manipulation and formatting
library(knitr) #Report tools and formatting
library(corrplot) #Pretty correlation plots
library(tidymodels) #Multiuse package containing many models
library(sem) #Structural equation models for CFA
library(psych) #Exploratory factor models
library(randomForest) #Classification trees also in caret
library(gbm) #Logistic classifies for caret and other packages
library(DiagrammeR)
library(rattle)
library(kableExtra)
library(class)
library(ape)
library(readxl)
library(visdat)
library(naniar)
library(janitor)
library(correlationfunnel)
library(Hmisc)
library(xgboost)
library(vip)
library(RColorBrewer)
library(MVN)
```


#Load in Data  
```{r}
sviDat <- read.csv("SVI2018_US_COUNTY.csv") %>% #Load CSV provided by CDC website
  select(c(STATE,ST_ABBR,COUNTY,FIPS, E_TOTPOP)|starts_with('EP_')) %>% #For this analysis we will be using the percent values for the measures rather than raw values
  replace(., . ==-999, NA) %>% #Excluding counties with missing data
  na.omit()

#head(sviDat)
kable(head(sviDat), caption = "Preview of SVI Data", digits = 1, format = 'html') %>%
  kable_styling() %>%
  kableExtra::scroll_box(width = "100%", height = "375px")
```

#Exploratory Analysis  
##Summary Statistics  
```{r}
#Summary
kable(do.call(cbind, lapply(sviDat[,5:20], summary)), caption = "Summary Statistics for All Variables", digits = 1, format = 'html') %>%
  kable_styling() %>%
  kableExtra::scroll_box(width = "100%", height = "375px")
```


## Density Plots  
```{r}
#Create Density Plots
for(i in 5:20) {
a <- ggplot(sviDat,aes(sviDat[,i])) + 
  geom_density(kernel = "gaussian", fill = 'lightpink') +
  geom_vline(aes(xintercept=mean(sviDat[,i])), color="blue", linetype="dashed", size=1) +
  ggtitle(colnames(sviDat)[i]) +
  labs( x = colnames(sviDat)[i])
print(a)
}
```

#Clustering Counties, States, and Variables 
```{r}
# Clustering the variables base on correlation
SVI_hc_corr <- hclust(as.dist(1-abs(cor(scale(sviDat[,6:20])))))
plot(as.phylo(SVI_hc_corr), type = "fan", cex=.6)


# Using hierarchical Clustering. Since all variables are percentages, there is not a big need to center and scale here.
SVI_hc <- hclust(dist(scale(sviDat[,6:20])), method = "complete") #Not using the calculated RPL themes to cluster
plot(SVI_hc, main='Clustering Counties Based on SVI Census Measures', xlab="", sub="", cex=.2)


# Summarizing on state and taking the average county values
sviDat_state_pop <- sviDat %>%
  select(STATE,E_TOTPOP) %>%
  group_by(STATE) %>%
  summarise(st_TOTPOP = sum(E_TOTPOP)) 


sviDat_state <- sviDat %>%
  select(!c(COUNTY,FIPS,E_TOTPOP)) %>%
  group_by(STATE, ST_ABBR) %>%
  summarise(across(everything(), list(avg = mean, min = min, max = max))) 
  

# Clustering States  
SVI_hc_st <- hclust(dist(scale(sviDat_state[,3:50])), method = "complete")
SVI_hc_st$labels <- sviDat_state$STATE
plot(SVI_hc_st, main='Clustering Counties Based on SVI Census Measures', xlab="", sub="", cex=.6)


sviDat_st_c <- sviDat_state
sviDat_st_c$group <- cutree(SVI_hc_st, 6)

tabyl(sviDat_st_c$group)

colors <- brewer.pal(n=6, name='Dark2')
cluscomp <- cutree(SVI_hc_st, 6)
plot(as.phylo(SVI_hc_st), type = 'fan', tip.color = colors[cluscomp], label.offset =.8, cex = .6)

st_grp <- sviDat_st_c %>%
  group_by(STATE) %>%
  summarise(st_grp = max(group))

```


##Exploring the clusters  
```{r}

dat_box <- sviDat_st_c %>%
  select(ends_with('avg') | c(STATE, ST_ABBR, group)) %>%
  as.data.frame()



#Create Boxplots for 6 clusters
for(i in 1:16) {
a <- ggplot(dat_box,aes(x = as.factor(group), y=dat_box[,i])) +
  geom_jitter(aes(color=STATE), position = position_jitter(seed = 1)) +
  geom_boxplot() +
  ggtitle(colnames(dat_box)[i]) +
  theme(legend.position = "none") +
  geom_text(position = position_jitter(seed = 1),check_overlap = TRUE, size = 3, aes(label=ST_ABBR))
print(a)
}


```


```{r echo=FALSE, message=FALSE, warning=FALSE, error=FALSE, include=FALSE}
#etst
```



#Assessing SVI and COVID Impacts  
## Get Data from CDC API
```{r}

library("RSocrata")

cnty_covDat <- read.socrata(
  "https://data.cdc.gov/resource/kn79-hsxy.json",
  app_token = token, 
  email     = email,
  password  = pswd
)

cnty_Dat <- cnty_covDat  %>%
  select(county_fips_code, total_death, covid_death) %>%
  rename(FIPS=county_fips_code) %>%
  mutate(FIPS = as.integer(FIPS)) %>%
  inner_join(sviDat, by = 'FIPS', keep=F) %>%
  inner_join(st_grp, by = 'STATE')


st_covDat <- read.socrata(
  "https://data.cdc.gov/resource/9mfq-cb36.json",
  app_token = token, 
  email     = email,
  password  = pswd
) %>% 
  select(state,tot_cases,tot_death) %>%
  group_by(state) %>%
  summarise(tot_cases = max(tot_cases), tot_death=max(tot_death)) %>%
  rename(ST_ABBR = state) %>%
  inner_join(dat_box, by = 'ST_ABBR') %>%
  inner_join(sviDat_state_pop, by = 'STATE') %>%
  mutate(tot_cases = as.numeric(tot_cases), tot_death=as.numeric(tot_death)) %>%
  mutate(pct_case = tot_cases/st_TOTPOP, pct_death_t=tot_death/st_TOTPOP, cov_mort = tot_death/tot_cases, .keep='all')

```


## Observing Death and Case Distributions
```{r}
ggplot(st_covDat,aes(tot_death)) + 
  geom_density(kernel = "gaussian", fill = 'lightpink') +
  geom_vline(aes(xintercept=mean(tot_death)), color="blue", linetype="dashed", size=1) +
  ggtitle('Covid Deaths') +
  labs() 


ggplot(st_covDat,aes(tot_cases)) + 
  geom_density(kernel = "gaussian", fill = 'lightpink') +
  geom_vline(aes(xintercept=mean(tot_cases)), color="blue", linetype="dashed", size=1) +
  ggtitle('Covid Deaths') +
  labs() 

```

## Trying a Poisson model using a rate of deaths per cases
```{r}
log_dat <- st_covDat %>%
  select(c(tot_death, tot_cases)|ends_with('avg')) %>%
  mutate(logcase = log(tot_cases), .keep='unused')

poisson_fit <- glm(tot_death ~ . - logcase + offset(logcase), family = poisson(link = "log"), data = log_dat)
summary(poisson_fit)

dp = sum(residuals(poisson_fit,type ="pearson")^2)/poisson_fit$df.residual
dp

library(AER)
dispersiontest(poisson_fit)


summary(poisson_fit,dispersion = dp)
```
Very high dispersion resulting in a probably faulty model  


## Trying a quasipoisson model  
```{r}
poisson_fit <- glm(tot_death ~ . - logcase + offset(logcase), family = quasipoisson(), data = log_dat)
summary(poisson_fit)

```


## Trying a binomial model
```{r}
b_dat <- st_covDat %>%
  select(c(tot_death, tot_cases)|ends_with('avg')) 

b_fit <- glm(cbind(tot_death, tot_cases) ~ ., family = binomial, data = b_dat)
summary(b_fit)

```


## Checking multicollinearity  
```{r}
res2.A <-rcorr(as.matrix(b_dat[,3:18]),type = "pearson")
corrplot(res2.A$r, type="upper", order="hclust",tl.cex=.8)
```


## Reducing multicolinearity with dimension reduction  
### Using Exploratory Factor Analysis to reduce collinearity
```{r}
#Preprocessing
X <- b_dat[,3:18]

X <- scale(X)

#Parallel Analysis
fa.parallel(X, n.iter =100, fm = "ml", fa="fa")


f <- 3

#EFA Full Data
fa.out.none <- fa(X, fm="ml",nfactors = f, rotate="none")
fa.out.varimax <- fa(X, fm="ml",nfactors = f, rotate="varimax")
fa.out.quartimax <- fa(X, fm="ml",nfactors = f, rotate="quartimax")

Results <- rbind(fa.out.none$TLI,fa.out.none$PVAL,fa.out.none$RMSEA[1])
rownames(Results) <- c("Tucker Lewis Index", "ChiSq Pval","RMSEA")
colnames(Results) <- "Fit"
round(Results,2)

par(mfrow= c(1,3))
fa.diagram(fa.out.none, cut = 0.2, simple = F, main = "No Rotation")
fa.diagram(fa.out.varimax, cut =0.2, simple = F, main = "Varimax rotation")
fa.diagram(fa.out.quartimax,cut =0.16, simple = F, main = "Qaurtimax roation")
```



### Using PCA to reduce collinerarity  
```{r}
pc <- prcomp(X)
summary(pc)

screeplot(pc, type='lines')

pc$rotation


pca_dat <- data.frame(tot_death = b_dat$tot_death, tot_cases = b_dat$tot_cases,  pc$x)

pca_dat <- pca_dat[,1:8]


```


### Checking PCA relationships  
```{r}
res2.A <-rcorr(as.matrix(pca_dat[,3:8]),type = "pearson")
corrplot(res2.A$r, type="upper", order="hclust",tl.cex=.8)
```



##  Trying a binomial model with the first 6 PCs
```{r}
pca_fit <- glm(cbind(tot_death, tot_cases) ~ ., family = binomial, data = pca_dat)
summary(pca_fit)
```



```{r eval=FALSE, echo=FALSE}

   file.rename(from="SVI_COVID.md", 
               to="README.md")
               
```


